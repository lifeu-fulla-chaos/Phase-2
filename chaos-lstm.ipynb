{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11317940,"sourceType":"datasetVersion","datasetId":6954542},{"sourceId":327038,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":274514,"modelId":293700}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass LSTM(nn.Module):\n    def __init__(self, hidden_size, layers):\n        super(LSTM,self).__init__()\n        self.lstm = nn.LSTM(input_size=3, hidden_size=hidden_size,num_layers=layers,batch_first=True,bidirectional=True)\n        self.fc=nn.Linear(hidden_size*2,6)\n        self.hidden_size = hidden_size\n        self.layers = layers\n\n    def forward(self,x):\n        x,_ = self.lstm(x)\n        x=x[:,-1,:]\n        x = self.fc(x)\n        return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:30:20.810670Z","iopub.execute_input":"2025-04-07T00:30:20.810953Z","iopub.status.idle":"2025-04-07T00:30:24.788882Z","shell.execute_reply.started":"2025-04-07T00:30:20.810931Z","shell.execute_reply":"2025-04-07T00:30:24.787995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model=LSTM(128, 2)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\ncriterion = nn.MSELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:30:24.790062Z","iopub.execute_input":"2025-04-07T00:30:24.790536Z","iopub.status.idle":"2025-04-07T00:30:27.147636Z","shell.execute_reply.started":"2025-04-07T00:30:24.790505Z","shell.execute_reply":"2025-04-07T00:30:27.146763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\n\nclass LorenzSlidingWindowDataset(Dataset):\n    def __init__(self, folder_path, window_size, stride_length, index_map=None, file_info=None):\n        self.folder_path = folder_path\n        self.window_size = window_size\n        self.stride_length = stride_length\n\n        self.file_info = file_info if file_info is not None else self._scan_files()\n        self.index_map = index_map if index_map is not None else self._build_index_map()\n\n        if self.file_info is not None:\n            self.data_frames = [\n                pd.read_csv(os.path.join(self.folder_path, info['filename']))\n                for info in self.file_info\n            ]\n            \n    def _scan_files(self):\n        files = os.listdir(self.folder_path)\n        info = []\n        for f in files:\n            parts = f.split('_')\n            index = parts[0]\n            target = parts[1:]\n            info.append({'filename': f, 'index': index, 'target': target})\n        return info\n\n    def _build_index_map(self):\n        index_map = []\n        fixed_length = 10000\n        max_start = fixed_length - self.window_size\n    \n        for file_idx in range(len(self.file_info)):\n            for i in range(0, max_start + 1, self.stride_length):\n                index_map.append((file_idx, i))\n    \n        return index_map\n\n\n    def __len__(self):\n        return len(self.index_map)\n\n    def __getitem__(self, idx):\n        file_idx, row_start = self.index_map[idx]\n        file_meta = self.file_info[file_idx]\n        file_path = file_meta['filename']\n\n        df = self.data_frames[file_idx]\n        x = df.iloc[:self.window_size, 0:3].values \n        y = [float(i) for i in file_path[:-4].split(\"_\")[1:]]\n\n        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:30:27.149300Z","iopub.execute_input":"2025-04-07T00:30:27.149780Z","iopub.status.idle":"2025-04-07T00:30:27.439625Z","shell.execute_reply.started":"2025-04-07T00:30:27.149754Z","shell.execute_reply":"2025-04-07T00:30:27.438775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nfull_dataset = LorenzSlidingWindowDataset(\n    folder_path=\"/kaggle/input/lorenz-data1/lorenz_data_separate/\",\n    window_size=50,\n    stride_length=25\n)\n\nfrom sklearn.model_selection import train_test_split\ntrain_indices, val_indices = train_test_split(\n    full_dataset.index_map, test_size=0.2, random_state=42\n)\n\ntrain_dataset = LorenzSlidingWindowDataset(\n    folder_path=\"/kaggle/input/lorenz-data1/lorenz_data_separate/\",\n    window_size=50,\n    stride_length=25,\n    index_map=train_indices,\n    file_info=full_dataset.file_info\n)\n\nval_dataset = LorenzSlidingWindowDataset(\n    folder_path=\"/kaggle/input/lorenz-data1/lorenz_data_separate/\",\n    window_size=50,\n    stride_length=25,\n    index_map=val_indices,\n    file_info=full_dataset.file_info\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:36:18.486282Z","iopub.execute_input":"2025-04-07T00:36:18.486623Z","iopub.status.idle":"2025-04-07T00:39:01.331476Z","shell.execute_reply.started":"2025-04-07T00:36:18.486596Z","shell.execute_reply":"2025-04-07T00:39:01.330648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:39:49.635819Z","iopub.execute_input":"2025-04-07T00:39:49.636137Z","iopub.status.idle":"2025-04-07T00:39:50.456534Z","shell.execute_reply.started":"2025-04-07T00:39:49.636113Z","shell.execute_reply":"2025-04-07T00:39:50.455419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/chaos-lstm/pytorch/92/1/92.pth\", weights_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:45:44.901120Z","iopub.execute_input":"2025-04-07T00:45:44.901412Z","iopub.status.idle":"2025-04-07T00:45:45.007118Z","shell.execute_reply.started":"2025-04-07T00:45:44.901377Z","shell.execute_reply":"2025-04-07T00:45:45.006458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nepochs = 20\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0.0\n    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [TRAIN]\")\n    for x_batch, y_batch in train_bar:\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        preds = model(x_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * x_batch.size(0)\n        train_bar.set_postfix(loss=loss.item())\n\n    train_loss /= len(train_loader.dataset)\n\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [VAL]\")\n        for x_batch, y_batch in val_bar:\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n\n            preds = model(x_batch)\n            loss = criterion(preds, y_batch)\n\n            val_loss += loss.item() * x_batch.size(0)\n            val_bar.set_postfix(loss=loss.item())\n\n    val_loss /= len(val_loader.dataset)\n\n    print(f\"\\nEpoch {epoch+1} Summary: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:11:38.367281Z","iopub.execute_input":"2025-04-06T16:11:38.367648Z","iopub.status.idle":"2025-04-06T16:11:45.640541Z","shell.execute_reply.started":"2025-04-06T16:11:38.367622Z","shell.execute_reply":"2025-04-06T16:11:45.639261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"92.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:08:55.987743Z","iopub.execute_input":"2025-04-06T16:08:55.988058Z","iopub.status.idle":"2025-04-06T16:08:55.997999Z","shell.execute_reply.started":"2025-04-06T16:08:55.988032Z","shell.execute_reply":"2025-04-06T16:08:55.997389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    total_loss = 0.0\n    criterion = nn.MSELoss()\n\n    with torch.no_grad():\n        for x_batch, y_batch in tqdm(dataloader, desc=\"Evaluating\"):\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n\n            preds = model(x_batch)\n            loss = criterion(preds, y_batch)\n            total_loss += loss.item() * x_batch.size(0)\n\n            all_preds.append(preds.cpu())\n            all_targets.append(y_batch.cpu())\n\n    all_preds = torch.cat(all_preds).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n\n    mse = mean_squared_error(all_targets, all_preds)\n    mae = mean_absolute_error(all_targets, all_preds)\n    avg_loss = total_loss / len(dataloader.dataset)\n\n    mse_per_target = ((all_preds - all_targets) ** 2).mean(axis=0)\n    mae_per_target = np.abs(all_preds - all_targets).mean(axis=0)\n\n    print(f\"\\nEvaluation Results\")\n    print(f\"Overall MSE: {mse:.4f}, MAE: {mae:.4f}, Avg Loss: {avg_loss:.4f}\")\n    print(\"\\n📊 Per-Target MSE / MAE:\")\n    for i in range(all_preds.shape[1]):\n        print(f\"Target {i+1}: MSE = {mse_per_target[i]:.4f}, MAE = {mae_per_target[i]:.4f}\")\n\n    return all_preds, all_targets, mse_per_target, mae_per_target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:45:48.894293Z","iopub.execute_input":"2025-04-07T00:45:48.894706Z","iopub.status.idle":"2025-04-07T00:45:48.905830Z","shell.execute_reply.started":"2025-04-07T00:45:48.894670Z","shell.execute_reply":"2025-04-07T00:45:48.904590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nmodel = model.to(\"cuda\")\nval_preds, val_targets, mses, maes = evaluate_model(model, val_loader, \"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:45:50.591238Z","iopub.execute_input":"2025-04-07T00:45:50.591687Z","iopub.status.idle":"2025-04-07T00:47:52.988617Z","shell.execute_reply.started":"2025-04-07T00:45:50.591646Z","shell.execute_reply":"2025-04-07T00:47:52.987814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_predictions(preds, targets, num_targets=6, sample_size=200):\n    \"\"\"\n    Plots predicted vs true values for each target.\n\n    Parameters:\n        preds (np.ndarray): Model predictions (N x num_targets)\n        targets (np.ndarray): True labels (N x num_targets)\n        num_targets (int): Number of target variables\n        sample_size (int): Number of samples to plot per target\n    \"\"\"\n    assert preds.shape == targets.shape, \"Predictions and targets must have the same shape.\"\n    sample_size = min(sample_size, preds.shape[0])\n\n    plt.figure(figsize=(18, 12))\n    \n    for i in range(num_targets):\n        plt.subplot(2, 3, i + 1)\n        \n        # Scatter plot\n        plt.scatter(\n            targets[:sample_size, i],\n            preds[:sample_size, i],\n            alpha=0.6,\n            s=10,\n            c='tab:blue',\n            label='Prediction'\n        )\n        \n        min_val = min(targets[:sample_size, i].min(), preds[:sample_size, i].min())\n        max_val = max(targets[:sample_size, i].max(), preds[:sample_size, i].max())\n        plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')\n\n        plt.xlabel(\"True\")\n        plt.ylabel(\"Predicted\")\n        plt.title(f\"Target {i+1}\")\n        plt.legend()\n        plt.grid(True)\n\n    plt.tight_layout()\n    plt.suptitle(\"Predicted vs True Values (First 200 Samples)\", fontsize=18, y=1.02)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:48:03.572334Z","iopub.execute_input":"2025-04-07T00:48:03.572701Z","iopub.status.idle":"2025-04-07T00:48:03.580179Z","shell.execute_reply.started":"2025-04-07T00:48:03.572673Z","shell.execute_reply":"2025-04-07T00:48:03.579219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_predictions(val_preds, val_targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:48:07.276287Z","iopub.execute_input":"2025-04-07T00:48:07.276673Z","iopub.status.idle":"2025-04-07T00:48:09.029372Z","shell.execute_reply.started":"2025-04-07T00:48:07.276642Z","shell.execute_reply":"2025-04-07T00:48:09.028487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}